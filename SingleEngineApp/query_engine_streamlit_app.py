"""
Streamlit Webç•Œé¢
ä¸ºQuery Agentæä¾›å‹å¥½çš„Webç•Œé¢
"""

import os
import sys
import streamlit as st
from datetime import datetime
import json
import locale

# è®¾ç½®UTF-8ç¼–ç ç¯å¢ƒ
os.environ['PYTHONIOENCODING'] = 'utf-8'
os.environ['PYTHONUTF8'] = '1'

# è®¾ç½®ç³»ç»Ÿç¼–ç 
try:
    locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')
except locale.Error:
    try:
        locale.setlocale(locale.LC_ALL, 'C.UTF-8')
    except locale.Error:
        pass

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from QueryEngine import TheoryExpertAgent, Config
from config import QUERY_ENGINE_API_KEY, QUERY_ENGINE_BASE_URL, QUERY_ENGINE_MODEL_NAME, TAVILY_API_KEY


def main():
    """ä¸»å‡½æ•°"""
    st.set_page_config(
        page_title="Query Agent - ä¿¡æ¯æ£€ç´¢ä¸“å®¶",
        page_icon="ğŸ”",
        layout="wide"
    )

    # è‡ªå®šä¹‰æ ·å¼
    st.markdown("""
    <style>
        /* éšè—Streamlité»˜è®¤é¡µçœ‰å’Œå·¥å…·æ  */
        header[data-testid="stHeader"] {
            background-color: transparent;
            background: transparent;
        }

        /* éšè—å³ä¸Šè§’çš„éƒ¨ç½²æŒ‰é’®ç­‰ */
        .stDeployButton {
            display: none;
        }

        /* éšè—é¡¶éƒ¨å·¥å…·æ  */
        #MainMenu {
            visibility: hidden;
        }

        footer {
            visibility: hidden;
        }

        /* ä¸»é¢˜é…è‰² */
        :root {
            --primary-color: #3b82f6;
            --secondary-color: #10b981;
            --bg-dark: #0f172a;
            --bg-panel: #1e293b;
        }

        /* æ ‡é¢˜æ ·å¼ */
        .main-title {
            font-size: 2.5rem;
            font-weight: 700;
            background: linear-gradient(135deg, #3b82f6 0%, #8b5cf6 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 0.5rem;
            text-align: center;
        }

        .subtitle {
            font-size: 1.1rem;
            color: #94a3b8;
            text-align: center;
            margin-bottom: 2rem;
        }

        /* å¡ç‰‡æ ·å¼ */
        .stApp {
            background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%);
        }

        /* è¿›åº¦æ¡æ ·å¼ */
        .stProgress > div > div > div {
            background: linear-gradient(90deg, #3b82f6 0%, #8b5cf6 100%);
        }

        /* æŒ‰é’®æ ·å¼ */
        .stButton > button {
            background: linear-gradient(135deg, #3b82f6 0%, #8b5cf6 100%);
            color: white;
            border: none;
            border-radius: 8px;
            padding: 0.75rem 2rem;
            font-weight: 600;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(59, 130, 246, 0.3);
        }

        .stButton > button:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(59, 130, 246, 0.4);
        }

        /* æ–‡æœ¬æ¡†æ ·å¼ */
        .stTextArea textarea {
            border-radius: 8px;
            border: 2px solid #334155;
            background: #1e293b;
            color: #e2e8f0;
            font-size: 0.95rem;
        }

        /* æ ‡ç­¾é¡µæ ·å¼ */
        .stTabs [data-baseweb="tab-list"] {
            gap: 8px;
            background: #1e293b;
            border-radius: 8px;
            padding: 0.5rem;
        }

        .stTabs [data-baseweb="tab"] {
            border-radius: 6px;
            padding: 0.5rem 1rem;
            background: transparent;
            color: #94a3b8;
        }

        .stTabs [aria-selected="true"] {
            background: linear-gradient(135deg, #3b82f6 0%, #8b5cf6 100%);
            color: white;
        }

        /* Expanderæ ·å¼ */
        .streamlit-expanderHeader {
            background: #1e293b;
            border-radius: 8px;
            border: 1px solid #334155;
        }

        /* æˆåŠŸ/é”™è¯¯/è­¦å‘Šæ¶ˆæ¯æ ·å¼ */
        .stSuccess, .stError, .stWarning {
            border-radius: 8px;
            padding: 1rem;
        }

        /* å¢å¼ºæ‰€æœ‰markdownæ–‡å­—é¢œè‰² - ç¡®ä¿æ¸…æ™°å¯è¯» */
        .stMarkdown, .stMarkdown p, .stMarkdown div, .stMarkdown span {
            color: #e5e7eb !important;  /* æ˜äº®çš„æµ…ç°è‰² */
        }

        /* å¢å¼ºmarkdownåŠ ç²—æ–‡å­— */
        .stMarkdown strong, .stMarkdown b {
            color: #f3f4f6 !important;  /* æ›´äº®çš„ç™½ç°è‰² */
            font-weight: 700;
        }

        /* å¢å¼ºæ‰€æœ‰æ–‡æœ¬å…ƒç´  */
        p, div, span, label {
            color: #d1d5db !important;
        }
    </style>
    """, unsafe_allow_html=True)

    st.markdown('<h1 class="main-title">Query Agent</h1>', unsafe_allow_html=True)
    st.markdown('<p class="subtitle">ä¿¡æ¯æ£€ç´¢ä¸“å®¶ | æ™ºèƒ½ç½‘é¡µæœç´¢ | å¤šæºæ•°æ®èšåˆ</p>', unsafe_allow_html=True)

    # æ£€æŸ¥URLå‚æ•°
    try:
        # å°è¯•ä½¿ç”¨æ–°ç‰ˆæœ¬çš„query_params
        query_params = st.query_params
        auto_query = query_params.get('query', '')
        auto_search = query_params.get('auto_search', 'false').lower() == 'true'
    except AttributeError:
        # å…¼å®¹æ—§ç‰ˆæœ¬
        query_params = st.experimental_get_query_params()
        auto_query = query_params.get('query', [''])[0]
        auto_search = query_params.get('auto_search', ['false'])[0].lower() == 'true'

    # ----- é…ç½®è¢«ç¡¬ç¼–ç  -----
    # å¼ºåˆ¶ä½¿ç”¨ DeepSeek
    model_name = QUERY_ENGINE_MODEL_NAME or "deepseek-chat"
    # é»˜è®¤é«˜çº§é…ç½®
    max_reflections = 2
    max_content_length = 20000

    # ç®€åŒ–çš„ç ”ç©¶æŸ¥è¯¢å±•ç¤ºåŒºåŸŸ
    
    # å¦‚æœæœ‰è‡ªåŠ¨æŸ¥è¯¢ï¼Œä½¿ç”¨å®ƒä½œä¸ºé»˜è®¤å€¼ï¼Œå¦åˆ™æ˜¾ç¤ºå ä½ç¬¦
    display_query = auto_query if auto_query else "ç­‰å¾…ä»ä¸»é¡µé¢æ¥æ”¶åˆ†æå†…å®¹..."
    
    # åªè¯»çš„æŸ¥è¯¢å±•ç¤ºåŒºåŸŸ
    st.text_area(
        "å½“å‰æŸ¥è¯¢",
        value=display_query,
        height=100,
        disabled=True,
        help="æŸ¥è¯¢å†…å®¹ç”±ä¸»é¡µé¢çš„æœç´¢æ¡†æ§åˆ¶",
        label_visibility="hidden"
    )

    # è‡ªåŠ¨æœç´¢é€»è¾‘
    start_research = False
    query = auto_query
    
    if auto_search and auto_query and 'auto_search_executed' not in st.session_state:
        st.session_state.auto_search_executed = True
        start_research = True
    elif auto_query and not auto_search:
        st.warning("ç­‰å¾…æœç´¢å¯åŠ¨ä¿¡å·...")

    # éªŒè¯é…ç½®
    if start_research:
        if not query.strip():
            st.error("è¯·è¾“å…¥ç ”ç©¶æŸ¥è¯¢")
            return

        # ç”±äºå¼ºåˆ¶ä½¿ç”¨DeepSeekï¼Œæ£€æŸ¥ç›¸å…³çš„APIå¯†é’¥
        if not QUERY_ENGINE_API_KEY:
            st.error("è¯·åœ¨æ‚¨çš„é…ç½®æ–‡ä»¶(config.py)ä¸­è®¾ç½®QUERY_ENGINE_API_KEY")
            return
        if not TAVILY_API_KEY:
            st.error("è¯·åœ¨æ‚¨çš„é…ç½®æ–‡ä»¶(config.py)ä¸­è®¾ç½®TAVILY_API_KEY")
            return

        # è‡ªåŠ¨ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥
        engine_key = QUERY_ENGINE_API_KEY
        tavily_key = TAVILY_API_KEY

        # åˆ›å»ºé…ç½®
        config = Config(
            llm_api_key=engine_key,
            llm_base_url=QUERY_ENGINE_BASE_URL,
            llm_model_name=model_name,
            tavily_api_key=tavily_key,
            max_reflections=max_reflections,
            max_content_length=max_content_length,
            output_dir="query_engine_streamlit_reports"
        )

        # æ‰§è¡Œç ”ç©¶
        execute_research(query, config)


def execute_research(query: str, config: Config):
    """æ‰§è¡Œæ™ºèƒ½æ£€ç´¢"""
    try:
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()

        # åˆå§‹åŒ–Agent
        status_text.markdown("**æ­£åœ¨åˆå§‹åŒ–ç†è®ºä¸“å®¶...**")
        agent = TheoryExpertAgent(config)
        st.session_state.agent = agent

        progress_bar.progress(10)

        # ç”ŸæˆæŠ¥å‘Šç»“æ„
        status_text.markdown("**æ­£åœ¨æ„å»ºä¿¡æ¯æ¶æ„...**")
        agent._generate_report_structure(query)
        progress_bar.progress(20)

        # å¤„ç†æ®µè½
        total_paragraphs = len(agent.state.paragraphs)
        for i in range(total_paragraphs):
            status_text.markdown(f"**æ£€ç´¢è¿›åº¦ {i + 1}/{total_paragraphs}:** {agent.state.paragraphs[i].title}")

            # åˆå§‹æœç´¢å’Œæ€»ç»“
            agent._initial_search_and_summary(i)
            progress_value = 20 + (i + 0.5) / total_paragraphs * 60
            progress_bar.progress(int(progress_value))

            # åæ€å¾ªç¯
            agent._reflection_loop(i)
            agent.state.paragraphs[i].research.mark_completed()

            progress_value = 20 + (i + 1) / total_paragraphs * 60
            progress_bar.progress(int(progress_value))

        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        status_text.markdown("**æ­£åœ¨ç”Ÿæˆæ™ºèƒ½åˆ†ææŠ¥å‘Š...**")
        final_report = agent._generate_final_report()
        progress_bar.progress(90)

        # ä¿å­˜æŠ¥å‘Š
        status_text.markdown("**æ­£åœ¨ä¿å­˜åˆ†æç»“æœ...**")
        agent._save_report(final_report)
        progress_bar.progress(100)

        status_text.markdown("**æ™ºèƒ½æ£€ç´¢å®Œæˆ!**")

        # æ˜¾ç¤ºç»“æœ
        display_results(agent, final_report)

    except Exception as e:
        st.error(f"ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")


def display_results(agent: TheoryExpertAgent, final_report: str):
    """æ˜¾ç¤ºç†è®ºç ”ç©¶ç»“æœ"""
    st.markdown("---")
    st.markdown("## æ™ºèƒ½åˆ†æç»“æœ")

    # ç»“æœæ ‡ç­¾é¡µ
    tab1, tab2 = st.tabs(["åˆ†ææŠ¥å‘Š", "æ•°æ®æ¥æº"])

    with tab1:
        st.markdown(final_report)

    with tab2:
        # æ®µè½è¯¦æƒ…
        st.subheader("æ®µè½è¯¦æƒ…")
        for i, paragraph in enumerate(agent.state.paragraphs):
            with st.expander(f"æ®µè½ {i + 1}: {paragraph.title}"):
                st.write("**é¢„æœŸå†…å®¹:**", paragraph.content)
                st.write("**æœ€ç»ˆå†…å®¹:**", paragraph.research.latest_summary[:300] + "..."
                if len(paragraph.research.latest_summary) > 300
                else paragraph.research.latest_summary)
                st.write("**æœç´¢æ¬¡æ•°:**", paragraph.research.get_search_count())
                st.write("**åæ€æ¬¡æ•°:**", paragraph.research.reflection_iteration)

        # æœç´¢å†å²
        st.subheader("æœç´¢å†å²")
        all_searches = []
        for paragraph in agent.state.paragraphs:
            all_searches.extend(paragraph.research.search_history)

        if all_searches:
            for i, search in enumerate(all_searches):
                with st.expander(f"æœç´¢ {i + 1}: {search.query}"):
                    st.write("**URL:**", search.url)
                    st.write("**æ ‡é¢˜:**", search.title)
                    st.write("**å†…å®¹é¢„è§ˆ:**",
                             search.content[:200] + "..." if len(search.content) > 200 else search.content)
                    if search.score:
                        st.write("**ç›¸å…³åº¦è¯„åˆ†:**", search.score)


if __name__ == "__main__":
    main()
